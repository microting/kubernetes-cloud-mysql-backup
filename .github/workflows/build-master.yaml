name: Build on commit to master
on:
  push:
    branches:
      - master
jobs:
  build-master:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        test: ["mysql:5.7.32","mysql:8.0.24","mariadb:10.1","mariadb:10.2","mariadb:10.3","mariadb:10.4","mariadb:10.5"]
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@master
        with:
          project_id: kubernetes-cloud-mysql-backup
          service_account_key: ${{ secrets.GCP_SA }}
          export_default_credentials: true
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}
          # aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }} # if you have/need it
          aws-region: eu-central-1
      - name: Install Age Encryption
        working-directory: /tmp
        run: |
          git clone https://filippo.io/age
          cd age
          git checkout 31500bfa2f6a36d2958483fc54d6e3cc74154cbc
          go build -o . filippo.io/age/cmd/...
          sudo cp age /usr/local/bin/
      - name: Build kubernetes-cloud-mysql-backup, pull mysql and setup Docker
        run: |
          # Build Container Locally for testing
          echo "Building kubernetes-cloud-mysql-backup..."
          docker build -t kubernetes-cloud-mysql-backup:test .
          docker image
          # Pull MySQL
          echo "Pulling ${{matrix.test}}"
          docker pull ${{matrix.test}}
          # Create Docker Network
          echo "Creating Docker network..."
          docker network create --driver bridge backup-net
      - name: Setup Test Database
        run: |
          # Start ${{matrix.test}} Database
          echo "Starting ${{matrix.test}} Container..."
          docker run --name db-server -p 3306 --network backup-net -e MYSQL_ROOT_PASSWORD=letmein -d ${{matrix.test}}
          # Wait for ${{matrix.test}} to Start. The ${{matrix.test}} container takes a long time to start
          echo "Waiting for ${{matrix.test}} Container to start..."
          sleep 90
          # Import Test DB
          echo "Importing test DB..."
          docker exec -i db-server mysql -u root -pletmein < tests/db/world.sql
          docker exec -i db-server mysql -u root -pletmein < tests/db/world0.sql
          docker exec -i db-server mysql -u root -pletmein < tests/db/world1.sql
          docker exec -i db-server mysql -u root -pletmein < tests/db/world2.sql
      - name: Test GCP Standard Backup
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e GCP_GCLOUD_AUTH="${{ secrets.GCP_SA }}" -e GCP_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master" -e GCP_BUCKET_NAME="${{ secrets.GBUCKET_NAME }}" --env-file tests/configs/gcp.env --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          gsutil cp gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master/world.sql /tmp/world.sql
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql"
          rm /tmp/world.sql
      - name: Test GCP Compressed Backup
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e GCP_GCLOUD_AUTH="${{ secrets.GCP_SA }}" -e GCP_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master" -e GCP_BUCKET_NAME="${{ secrets.GBUCKET_NAME }}" --env-file tests/configs/gcp.env -e BACKUP_COMPRESS=true --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          gsutil cp gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master/world.sql.gz /tmp/world.sql.gz
          # gunzip backup
          echo "Extracting backup"
          gunzip /tmp/world.sql.gz
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql"
          rm /tmp/world.sql
      - name: Test GCP Encrypted Backup
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e GCP_GCLOUD_AUTH="${{ secrets.GCP_SA }}" -e GCP_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master" -e GCP_BUCKET_NAME="${{ secrets.GBUCKET_NAME }}" --env-file tests/configs/gcp.env -e AGE_PUBLIC_KEY="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCezY3II94FtFhJfC7wc7tNQkR9c+XN6AUNhR269f5xBCe0RZTAHt+jpHnc2auePvz+3G34cOTF7lLrgioff/yv+K6hMItKg0OdiqGQ5gKBwzUOom3TgZ1Cht7vnAVejsWfbd7RBTIeDYUnoNiHf9dt8CJIaLaanDnjzLOLQcf7KPlZUbk6TexC1QpL6X8ir9tl7ao8v+QSgGtigO2QwF7QdSZSd/xlv0FsQKfgD25fIQRZEvcyiUnLYAK1wmziICORnW0fp/sL84E8Pj8GvbQK6AGuZn/s27oYmIdCTrwnR68Jvn6l8ST+QrwexzRM/k0yGkRMOU9AiG0o4skEdtGF3yzmC4PSwRys/Ygdy2jmrDaSJSPxpT/gvB5I2UbX2ZCHJ6/H6jNXP71aPI5Ib/eIjWuAyYPRPDvlDOenNN9s7UTD5P1wLoyxx2pnatMHAHu89+1GfdRPglvgUH6y5DYTjc0WZKTqTbeR+DzNoBNRc8exsgo9Y1NWsJn3tyL6vI0= benmaynard@Benjamins-MacBook-Pro.local" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          gsutil cp gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master/world.sql.age /tmp/world.sql.age
          # Decrypt backup
          echo "Decrypt backup"
          age --decrypt -i tests/keys/priv /tmp/world.sql.age > /tmp/world.sql
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql and .age
          echo "Removing /tmp/world.sql and /tmp/world.sql.age"
          rm /tmp/world.sql
          rm /tmp/world.sql.age
      - name: Test GCP Backup with Timestamp
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e GCP_GCLOUD_AUTH="${{ secrets.GCP_SA }}" -e GCP_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master" -e GCP_BUCKET_NAME="${{ secrets.GBUCKET_NAME }}" --env-file tests/configs/gcp.env -e BACKUP_TIMESTAMP="_%Y_%m_%d" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          DATE_STRING=$(date +_%Y_%m_%d)
          echo "Fetching database backup..."
          gsutil cp gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master/world$DATE_STRING.sql /tmp/world.sql
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql"
          rm /tmp/world.sql
      - name: Test GCP Compressed Backup with Timestamp
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e GCP_GCLOUD_AUTH="${{ secrets.GCP_SA }}" -e GCP_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master" -e GCP_BUCKET_NAME="${{ secrets.GBUCKET_NAME }}" --env-file tests/configs/gcp.env -e BACKUP_TIMESTAMP="_%Y_%m_%d" -e BACKUP_COMPRESS=true --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          DATE_STRING=$(date +_%Y_%m_%d)
          echo "Fetching database backup..."
          gsutil cp gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master/world$DATE_STRING.sql.gz /tmp/world.sql.gz
          # gunzip backup
          echo "Extracting backup"
          gunzip /tmp/world.sql.gz
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql"
          rm /tmp/world.sql
      - name: Test GCP Compressed and Encrypted Backup
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e GCP_GCLOUD_AUTH="${{ secrets.GCP_SA }}" -e GCP_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master" -e GCP_BUCKET_NAME="${{ secrets.GBUCKET_NAME }}" --env-file tests/configs/gcp.env -e BACKUP_COMPRESS=true -e AGE_PUBLIC_KEY="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCezY3II94FtFhJfC7wc7tNQkR9c+XN6AUNhR269f5xBCe0RZTAHt+jpHnc2auePvz+3G34cOTF7lLrgioff/yv+K6hMItKg0OdiqGQ5gKBwzUOom3TgZ1Cht7vnAVejsWfbd7RBTIeDYUnoNiHf9dt8CJIaLaanDnjzLOLQcf7KPlZUbk6TexC1QpL6X8ir9tl7ao8v+QSgGtigO2QwF7QdSZSd/xlv0FsQKfgD25fIQRZEvcyiUnLYAK1wmziICORnW0fp/sL84E8Pj8GvbQK6AGuZn/s27oYmIdCTrwnR68Jvn6l8ST+QrwexzRM/k0yGkRMOU9AiG0o4skEdtGF3yzmC4PSwRys/Ygdy2jmrDaSJSPxpT/gvB5I2UbX2ZCHJ6/H6jNXP71aPI5Ib/eIjWuAyYPRPDvlDOenNN9s7UTD5P1wLoyxx2pnatMHAHu89+1GfdRPglvgUH6y5DYTjc0WZKTqTbeR+DzNoBNRc8exsgo9Y1NWsJn3tyL6vI0= benmaynard@Benjamins-MacBook-Pro.local" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          gsutil cp gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master/world.sql.gz.age /tmp/world.sql.gz.age
          # Decrypt backup
          echo "Decrypt backup"
          age --decrypt -i tests/keys/priv /tmp/world.sql.gz.age > /tmp/world.sql.gz
          # gunzip backup
          echo "Extracting backup"
          gunzip /tmp/world.sql.gz
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql and .age
          echo "Removing /tmp/world.sql and /tmp/world.sql.gz.age"
          rm /tmp/world.sql
          rm /tmp/world.sql.gz.age
      - name: Test GCP Compressed and Encrypted Backup with Timestamp
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e GCP_GCLOUD_AUTH="${{ secrets.GCP_SA }}" -e GCP_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master" -e GCP_BUCKET_NAME="${{ secrets.GBUCKET_NAME }}" --env-file tests/configs/gcp.env -e BACKUP_COMPRESS=true -e AGE_PUBLIC_KEY="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCezY3II94FtFhJfC7wc7tNQkR9c+XN6AUNhR269f5xBCe0RZTAHt+jpHnc2auePvz+3G34cOTF7lLrgioff/yv+K6hMItKg0OdiqGQ5gKBwzUOom3TgZ1Cht7vnAVejsWfbd7RBTIeDYUnoNiHf9dt8CJIaLaanDnjzLOLQcf7KPlZUbk6TexC1QpL6X8ir9tl7ao8v+QSgGtigO2QwF7QdSZSd/xlv0FsQKfgD25fIQRZEvcyiUnLYAK1wmziICORnW0fp/sL84E8Pj8GvbQK6AGuZn/s27oYmIdCTrwnR68Jvn6l8ST+QrwexzRM/k0yGkRMOU9AiG0o4skEdtGF3yzmC4PSwRys/Ygdy2jmrDaSJSPxpT/gvB5I2UbX2ZCHJ6/H6jNXP71aPI5Ib/eIjWuAyYPRPDvlDOenNN9s7UTD5P1wLoyxx2pnatMHAHu89+1GfdRPglvgUH6y5DYTjc0WZKTqTbeR+DzNoBNRc8exsgo9Y1NWsJn3tyL6vI0= benmaynard@Benjamins-MacBook-Pro.local" -e BACKUP_TIMESTAMP="_%Y_%m_%d" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          DATE_STRING=$(date +_%Y_%m_%d)
          gsutil cp gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master/world$DATE_STRING.sql.gz.age /tmp/world.sql.gz.age
          # Decrypt backup
          echo "Decrypt backup"
          age --decrypt -i tests/keys/priv /tmp/world.sql.gz.age > /tmp/world.sql.gz
          # gunzip backup
          echo "Extracting backup"
          gunzip /tmp/world.sql.gz
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql and /tmp/world.sql.gz.age"
          rm /tmp/world.sql
          rm /tmp/world.sql.gz.age
      - name: Test GCP Encrypted Backup with Timestamp
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e GCP_GCLOUD_AUTH="${{ secrets.GCP_SA }}" -e GCP_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master" -e GCP_BUCKET_NAME="${{ secrets.GBUCKET_NAME }}" --env-file tests/configs/gcp.env -e AGE_PUBLIC_KEY="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCezY3II94FtFhJfC7wc7tNQkR9c+XN6AUNhR269f5xBCe0RZTAHt+jpHnc2auePvz+3G34cOTF7lLrgioff/yv+K6hMItKg0OdiqGQ5gKBwzUOom3TgZ1Cht7vnAVejsWfbd7RBTIeDYUnoNiHf9dt8CJIaLaanDnjzLOLQcf7KPlZUbk6TexC1QpL6X8ir9tl7ao8v+QSgGtigO2QwF7QdSZSd/xlv0FsQKfgD25fIQRZEvcyiUnLYAK1wmziICORnW0fp/sL84E8Pj8GvbQK6AGuZn/s27oYmIdCTrwnR68Jvn6l8ST+QrwexzRM/k0yGkRMOU9AiG0o4skEdtGF3yzmC4PSwRys/Ygdy2jmrDaSJSPxpT/gvB5I2UbX2ZCHJ6/H6jNXP71aPI5Ib/eIjWuAyYPRPDvlDOenNN9s7UTD5P1wLoyxx2pnatMHAHu89+1GfdRPglvgUH6y5DYTjc0WZKTqTbeR+DzNoBNRc8exsgo9Y1NWsJn3tyL6vI0= benmaynard@Benjamins-MacBook-Pro.local" -e BACKUP_TIMESTAMP="_%Y_%m_%d" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          DATE_STRING=$(date +_%Y_%m_%d)
          gsutil cp gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master/world$DATE_STRING.sql.age /tmp/world.sql.age
          # Decrypt backup
          echo "Decrypt backup"
          age --decrypt -i tests/keys/priv /tmp/world.sql.age > /tmp/world.sql
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql and .age
          echo "Removing /tmp/world.sql and /tmp/world.sql.age"
          rm /tmp/world.sql
          rm /tmp/world.sql.age
      - name: Test AWS Standard Backup
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY }} -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_KEY }} -e AWS_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master"  -e AWS_BUCKET_NAME="${{ secrets.AWS_BUCKETNAME }}" --env-file tests/configs/aws.env --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          aws s3 cp s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/world.sql /tmp/world.sql
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql"
          rm /tmp/world.sql
      - name: Test AWS Compressed Backup
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY }} -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_KEY }} -e AWS_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master"  -e AWS_BUCKET_NAME="${{ secrets.AWS_BUCKETNAME }}" --env-file tests/configs/aws.env -e BACKUP_COMPRESS=true --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          aws s3 cp s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/world.sql.gz /tmp/world.sql.gz
          # gunzip backup
          echo "Extracting backup"
          gunzip /tmp/world.sql.gz
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql"
          rm /tmp/world.sql
      - name: Test AWS Encrypted Backup
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY }} -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_KEY }} -e AWS_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master"  -e AWS_BUCKET_NAME="${{ secrets.AWS_BUCKETNAME }}" --env-file tests/configs/aws.env -e AGE_PUBLIC_KEY="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCezY3II94FtFhJfC7wc7tNQkR9c+XN6AUNhR269f5xBCe0RZTAHt+jpHnc2auePvz+3G34cOTF7lLrgioff/yv+K6hMItKg0OdiqGQ5gKBwzUOom3TgZ1Cht7vnAVejsWfbd7RBTIeDYUnoNiHf9dt8CJIaLaanDnjzLOLQcf7KPlZUbk6TexC1QpL6X8ir9tl7ao8v+QSgGtigO2QwF7QdSZSd/xlv0FsQKfgD25fIQRZEvcyiUnLYAK1wmziICORnW0fp/sL84E8Pj8GvbQK6AGuZn/s27oYmIdCTrwnR68Jvn6l8ST+QrwexzRM/k0yGkRMOU9AiG0o4skEdtGF3yzmC4PSwRys/Ygdy2jmrDaSJSPxpT/gvB5I2UbX2ZCHJ6/H6jNXP71aPI5Ib/eIjWuAyYPRPDvlDOenNN9s7UTD5P1wLoyxx2pnatMHAHu89+1GfdRPglvgUH6y5DYTjc0WZKTqTbeR+DzNoBNRc8exsgo9Y1NWsJn3tyL6vI0= benmaynard@Benjamins-MacBook-Pro.local" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          aws s3 cp s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/world.sql.age /tmp/world.sql.age
          # Decrypt backup
          echo "Decrypt backup"
          age --decrypt -i tests/keys/priv /tmp/world.sql.age > /tmp/world.sql
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql and .age
          echo "Removing /tmp/world.sql and /tmp/world.sql.age"
          rm /tmp/world.sql
          rm /tmp/world.sql.age
      - name: Test AWS Backup with Timestamp
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY }} -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_KEY }} -e AWS_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master"  -e AWS_BUCKET_NAME="${{ secrets.AWS_BUCKETNAME }}" --env-file tests/configs/aws.env -e BACKUP_TIMESTAMP="_%Y_%m_%d" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          DATE_STRING=$(date +_%Y_%m_%d)
          echo "Fetching database backup..."
          aws s3 cp s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/world$DATE_STRING.sql /tmp/world.sql
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql"
          rm /tmp/world.sql
      - name: Test AWS Compressed Backup with Timestamp
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY }} -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_KEY }} -e AWS_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master"  -e AWS_BUCKET_NAME="${{ secrets.AWS_BUCKETNAME }}" --env-file tests/configs/aws.env -e BACKUP_TIMESTAMP="_%Y_%m_%d" -e BACKUP_COMPRESS=true --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          DATE_STRING=$(date +_%Y_%m_%d)
          echo "Fetching database backup..."
          aws s3 cp s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/world$DATE_STRING.sql.gz /tmp/world.sql.gz
          # gunzip backup
          echo "Extracting backup"
          gunzip /tmp/world.sql.gz
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql"
          rm /tmp/world.sql
      - name: Test AWS Compressed and Encrypted Backup
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY }} -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_KEY }} -e AWS_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master"  -e AWS_BUCKET_NAME="${{ secrets.AWS_BUCKETNAME }}" --env-file tests/configs/aws.env -e BACKUP_COMPRESS=true -e AGE_PUBLIC_KEY="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCezY3II94FtFhJfC7wc7tNQkR9c+XN6AUNhR269f5xBCe0RZTAHt+jpHnc2auePvz+3G34cOTF7lLrgioff/yv+K6hMItKg0OdiqGQ5gKBwzUOom3TgZ1Cht7vnAVejsWfbd7RBTIeDYUnoNiHf9dt8CJIaLaanDnjzLOLQcf7KPlZUbk6TexC1QpL6X8ir9tl7ao8v+QSgGtigO2QwF7QdSZSd/xlv0FsQKfgD25fIQRZEvcyiUnLYAK1wmziICORnW0fp/sL84E8Pj8GvbQK6AGuZn/s27oYmIdCTrwnR68Jvn6l8ST+QrwexzRM/k0yGkRMOU9AiG0o4skEdtGF3yzmC4PSwRys/Ygdy2jmrDaSJSPxpT/gvB5I2UbX2ZCHJ6/H6jNXP71aPI5Ib/eIjWuAyYPRPDvlDOenNN9s7UTD5P1wLoyxx2pnatMHAHu89+1GfdRPglvgUH6y5DYTjc0WZKTqTbeR+DzNoBNRc8exsgo9Y1NWsJn3tyL6vI0= benmaynard@Benjamins-MacBook-Pro.local" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          aws s3 cp s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/world.sql.gz.age /tmp/world.sql.gz.age
          # Decrypt backup
          echo "Decrypt backup"
          age --decrypt -i tests/keys/priv /tmp/world.sql.gz.age > /tmp/world.sql.gz
          # gunzip backup
          echo "Extracting backup"
          gunzip /tmp/world.sql.gz
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql and .age
          echo "Removing /tmp/world.sql and /tmp/world.sql.gz.age"
          rm /tmp/world.sql
          rm /tmp/world.sql.gz.age
      - name: Test AWS Compressed and Encrypted Backup with Timestamp
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY }} -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_KEY }} -e AWS_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master"  -e AWS_BUCKET_NAME="${{ secrets.AWS_BUCKETNAME }}" --env-file tests/configs/aws.env -e BACKUP_COMPRESS=true -e AGE_PUBLIC_KEY="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCezY3II94FtFhJfC7wc7tNQkR9c+XN6AUNhR269f5xBCe0RZTAHt+jpHnc2auePvz+3G34cOTF7lLrgioff/yv+K6hMItKg0OdiqGQ5gKBwzUOom3TgZ1Cht7vnAVejsWfbd7RBTIeDYUnoNiHf9dt8CJIaLaanDnjzLOLQcf7KPlZUbk6TexC1QpL6X8ir9tl7ao8v+QSgGtigO2QwF7QdSZSd/xlv0FsQKfgD25fIQRZEvcyiUnLYAK1wmziICORnW0fp/sL84E8Pj8GvbQK6AGuZn/s27oYmIdCTrwnR68Jvn6l8ST+QrwexzRM/k0yGkRMOU9AiG0o4skEdtGF3yzmC4PSwRys/Ygdy2jmrDaSJSPxpT/gvB5I2UbX2ZCHJ6/H6jNXP71aPI5Ib/eIjWuAyYPRPDvlDOenNN9s7UTD5P1wLoyxx2pnatMHAHu89+1GfdRPglvgUH6y5DYTjc0WZKTqTbeR+DzNoBNRc8exsgo9Y1NWsJn3tyL6vI0= benmaynard@Benjamins-MacBook-Pro.local" -e BACKUP_TIMESTAMP="_%Y_%m_%d" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          DATE_STRING=$(date +_%Y_%m_%d)
          aws s3 cp s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/world$DATE_STRING.sql.gz.age /tmp/world.sql.gz.age
          # Decrypt backup
          echo "Decrypt backup"
          age --decrypt -i tests/keys/priv /tmp/world.sql.gz.age > /tmp/world.sql.gz
          # gunzip backup
          echo "Extracting backup"
          gunzip /tmp/world.sql.gz
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql
          echo "Removing /tmp/world.sql and /tmp/world.sql.gz.age"
          rm /tmp/world.sql
          rm /tmp/world.sql.gz.age
      - name: Test AWS Encrypted Backup with Timestamp
        run: |
          # Perform database backup
          echo "Performing database backup..."
          docker run -e AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY }} -e AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_KEY }} -e AWS_BUCKET_BACKUP_PATH="/${{ github.sha }}${{matrix.test}}_master"  -e AWS_BUCKET_NAME="${{ secrets.AWS_BUCKETNAME }}" --env-file tests/configs/aws.env -e AGE_PUBLIC_KEY="ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQCezY3II94FtFhJfC7wc7tNQkR9c+XN6AUNhR269f5xBCe0RZTAHt+jpHnc2auePvz+3G34cOTF7lLrgioff/yv+K6hMItKg0OdiqGQ5gKBwzUOom3TgZ1Cht7vnAVejsWfbd7RBTIeDYUnoNiHf9dt8CJIaLaanDnjzLOLQcf7KPlZUbk6TexC1QpL6X8ir9tl7ao8v+QSgGtigO2QwF7QdSZSd/xlv0FsQKfgD25fIQRZEvcyiUnLYAK1wmziICORnW0fp/sL84E8Pj8GvbQK6AGuZn/s27oYmIdCTrwnR68Jvn6l8ST+QrwexzRM/k0yGkRMOU9AiG0o4skEdtGF3yzmC4PSwRys/Ygdy2jmrDaSJSPxpT/gvB5I2UbX2ZCHJ6/H6jNXP71aPI5Ib/eIjWuAyYPRPDvlDOenNN9s7UTD5P1wLoyxx2pnatMHAHu89+1GfdRPglvgUH6y5DYTjc0WZKTqTbeR+DzNoBNRc8exsgo9Y1NWsJn3tyL6vI0= benmaynard@Benjamins-MacBook-Pro.local" -e BACKUP_TIMESTAMP="_%Y_%m_%d" --network backup-net kubernetes-cloud-mysql-backup:test
          # Fetch backup file from GCS
          echo "Fetching database backup..."
          DATE_STRING=$(date +_%Y_%m_%d)
          aws s3 cp s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/world$DATE_STRING.sql.age /tmp/world.sql.age
          # Decrypt backup
          echo "Decrypt backup"
          age --decrypt -i tests/keys/priv /tmp/world.sql.age > /tmp/world.sql
          # Strip the "Dump Completed on" line
          echo "Stripping Dump Completed On line from downloaded backup..."
          sed -i '/-- Dump completed on/d' /tmp/world.sql
          sed -i '/-- MariaDB dump/d' /tmp/world.sql
          sed -i '/-- MySQL dump/d' /tmp/world.sql
          sed -i '/-- Server version/d' /tmp/world.sql
          # Compare the database backups, diff will exit with 1 if the files do not match causing the workflow to fail
          echo "Comparing database backup to known good database..."
          if grep -q "mariadb" <<< "${{matrix.test}}"; then
            echo "comparing MariaDB test file"
            diff tests/db/world-mariadb.sql /tmp/world.sql
          else
            diff tests/db/world.sql /tmp/world.sql
          fi
          # Remove /tmp/world.sql and .age
          echo "Removing /tmp/world.sql and /tmp/world.sql.age"
          rm /tmp/world.sql
          rm /tmp/world.sql.age
      - name: GPC post test cleanup
        if: always()
        run: |
          NUM_ITEMS=`gsutil ls gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master | grep "\.sql" | wc -l`
          while (( $NUM_ITEMS > 0 ))
          do
            CURRENT_BACKUP_TO_DELETE=`gsutil ls gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master | grep "\.sql" | head -1`
            gsutil rm $CURRENT_BACKUP_TO_DELETE
            NUM_ITEMS=`gsutil ls gs://${{ secrets.GBUCKET_NAME }}/${{ github.sha }}${{matrix.test}}_master | grep "\.sql" | wc -l`
          done
      - name: AWS post test cleanup
        if: always()
        run: |
          NUM_ITEMS=`aws s3 ls ${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master | grep "\.sql" | wc -l`
          while (( $NUM_ITEMS > 0 ))
          do
            CURRENT_BACKUP_TO_DELETE=`aws s3 ls ${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master | grep "\.sql" | head -1`
            aws s3 rm s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master/$CURRENT_BACKUP_TO_DELETE
            NUM_ITEMS=`aws s3 ls ${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master | grep "\.sql" | wc -l`
          done
          aws s3 rm s3://${{ secrets.AWS_BUCKETNAME }}/${{ github.sha }}${{matrix.test}}_master
